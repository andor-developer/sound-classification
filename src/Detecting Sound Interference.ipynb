{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Sound Interference with Tensorflow for Hangout Sessions\n",
    "By: Andor Kesselman\n",
    "\n",
    "In this analysis, we look at sound interference from multiple hangout streams using google hangout. We train and test the data using a neural network.\n",
    "The goal of this network is to give Google the functionality to enable a \"mute\" action is multiple audio streams occur on the hangouts at the same time. Frequently, when my colleagues and myself use hangouts, we log in at the same time with our computer. The problem is that multiple microphones on at the same time create an issue with loud feedback loops that greatly disrupt a meeting. Furthermore, often it is difficult to determine which of the incoming channels is responsible for disturbing the audio system. \n",
    "We are not audio processing experts, but hope that this simple neural network may provide enough of a baseline to accurately detect multiple audio feedback loops. It would be our hope that it would enable an \"action\" on Google's side, to mute the interefering audio system and prompt a warning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which type of Classifier do we use? SVM or NN?\n",
    "\n",
    "### Note: For Prototyping purposes, I'm going to be using PyAudio from\n",
    "https://github.com/tyiannak/pyAudioAnalysis\n",
    "\n",
    "I would like to re-evaluate the classification algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we've plotted the values. Now we neeed to do some form of classification. \n",
    "To generate this, we create our own training and test set. \n",
    "First, we generate a single interference instance using google hangouts for ~5 mintues. \n",
    "We then then randomly sample 10 seconds from the 5 minutes.\n",
    "Each sample then input a random noise variant using one of three different methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylab import*\n",
    "from scipy.io import wavfile\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, './lib') #insert lib\n",
    "import audioFeatureExtraction\n",
    "import audioTrainTest as aT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define Paths\n",
    "basedir = '/Users/andorkesselman/Documents/rnd/sound/src/'\n",
    "dataset_dir = basedir + 'datasets/'\n",
    "inter_dir_base = dataset_dir + 'base/interference_audio'\n",
    "clean_dir_base = dataset_dir + 'base/clean_audio'\n",
    "inter_dir_gen = dataset_dir + 'generated/interference_audio'\n",
    "clean_dir_gen = dataset_dir + 'generated/clean_audio'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Generation\n",
    "\n",
    "For Dataset generation, we will take existing audio files, induce some noise into the datastream, and then store them locally on the machine. This bootstrapping will allow us to generate lots of training data off of a relatively little sample set. \n",
    "\n",
    "During the training phase, these files will be read and split into 5 fold cross validation set. \n",
    "\n",
    "There are a couple reservations that I have regarding dataset generation. Firstly, my top concern is variety of data. I can add noise, but I do not think there will be enough variety in the datasets to properly train the data. For example, I will not have different languages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate Samples from Base Files and Write them to the Output Directory. \n",
    "# Adjust the parameters to tune the interations\n",
    "\n",
    "def generateSamples(base_dir, out_dir, suffix):\n",
    "    \n",
    "    print('Generating Training Data')\n",
    "    audio_files = listFilesInDirectory(base_dir)\n",
    "    count = 0\n",
    "    iterations_per_file = 5 # the amount of sample files to be generate from each base file\n",
    "    \n",
    "    for file in audio_files:\n",
    "        wav = readWavFile(file)\n",
    "        while (count < iterations_per_file):\n",
    "            sample = sampleFile(wav)\n",
    "            sample = randomNoiseGenerator(sample)\n",
    "            writeSample(sample, join(out_dir + str(count) + \"_\" + suffix + \".wav\"))\n",
    "            count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Given a sample, randomly chooses a type of noise to induce on the sample set. \n",
    "# There is a bias toward the original sample type.\n",
    "def randomNoiseGenerator(sample):\n",
    "    r = random.randint(0, 3)\n",
    "    if r == 0:\n",
    "        return whiteNoise(sample)\n",
    "    if r == 1:\n",
    "        x = band_limited_noise(200, 2000, 44100, 44100)\n",
    "        x = np.int16(x * (2**15 - 1))\n",
    "        return x\n",
    "    else:\n",
    "        return sample\n",
    "\n",
    "#Generate White Noise. \n",
    "def whiteNoise(array): \n",
    "    mean = 0\n",
    "    std = 1 \n",
    "    num_samples = 1000\n",
    "    samples = np.random.normal(mean, std, size=num_samples)\n",
    "    return array\n",
    "\n",
    "#Generate Band Limited Noise\n",
    "def fftnoise(f):\n",
    "    f = np.array(f, dtype='complex')\n",
    "    Np = (len(f) - 1) // 2\n",
    "    phases = np.random.rand(Np) * 2 * np.pi\n",
    "    phases = np.cos(phases) + 1j * np.sin(phases)\n",
    "    f[1:Np+1] *= phases\n",
    "    f[-1:-1-Np:-1] = np.conj(f[1:Np+1])\n",
    "    return np.fft.ifft(f).real\n",
    "\n",
    "def band_limited_noise(min_freq, max_freq, samples=sampleFreq, samplerate=1):\n",
    "    freqs = np.abs(np.fft.fftfreq(samples, 1/samplerate))\n",
    "    f = np.zeros(samples)\n",
    "    idx = np.where(np.logical_and(freqs>=min_freq, freqs<=max_freq))[0]\n",
    "    f[idx] = 1\n",
    "    return fftnoise(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .Wav Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read Wav File from Location Specified in Method Call\n",
    "def readWavFile(wavfile_location):\n",
    "    print(\"Reading \" + wavfile_location)\n",
    "    sampleFreq, sample = wavfile.read(wavfile_location)\n",
    "    sample = sample / (2.**15) #normalize and center\n",
    "    ch1 = sample[:,0] #take one channel. There are two channels in this scenario\n",
    "    return ch1\n",
    " \n",
    "# Write Audio Sample To File\n",
    "def writeSample(sample, outdir):\n",
    "    wavfile.write(outdir, 44100, sample)\n",
    "\n",
    "# Randomly Returns a Sample of a File. TODO: Improve Sampling Method. \n",
    "# Must Remain a Sequence in this Case because Audio is time dependent. Randomly Sampling would be BAD.\n",
    "def sampleFile(wav):\n",
    "    #take random \n",
    "    size = int(len(wav) / 5) # take 1/5 of the full file size. TODO: What's the best implemenation?\n",
    "    i = int(len(wav) - size - 1)\n",
    "    r = random.randint(0, i) # make sure that we get a full set. Hence the - size\n",
    "    return wav[r:(r+size), ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Only store the name. Do not store the file, as that would remain in memory.\n",
    "def listFilesInDirectory(directory):\n",
    "    ret = []\n",
    "    for file in listdir(directory):\n",
    "            ret.append(join(directory, file))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "In the training data, we will split up all the files in the training set into 5 k-folds, with 3 kfolds for the original training data, 1 k fold for the first test, and then the final validation set.\n",
    "\n",
    "CNN\n",
    "http://yerevann.github.io/2015/10/11/spoken-language-identification-with-deep-convolutional-networks/\n",
    "http://research.microsoft.com/en-us/um/people/dongyu/nips2009/papers/montavon-paper.pdf\n",
    "\n",
    "SVM\n",
    "http://www.ee.columbia.edu/~sfchang/course/spr-F05/papers/guo-li-svm-audio00.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "def ExtractFeatures(sample):\n",
    "    print('Feature Extraction. Potentially use PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Round 1: NN\n",
    "class NeuralNetwork():\n",
    "    print('This is the Neural Network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Round 2: SVM\n",
    "class SVM():\n",
    "    print('This is an SVM approach')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./lib/audioFeatureExtraction.py:206: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  fbank = numpy.zeros(int(nFiltTotal), int(nfft))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-267-438a95c67b9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatureAndTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclean_dir_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minter_dir_base\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortTermWindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortTermStep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"svm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"svmSMtemp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minter_dir_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"svmSMtemp\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"svm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/andorkesselman/Documents/rnd/sound/src/lib/audioTrainTest.py\u001b[0m in \u001b[0;36mfeatureAndTrain\u001b[0;34m(listOfDirs, mtWin, mtStep, stWin, stStep, classifierType, modelName, computeBEAT, perTrain)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;31m# STEP A: Feature Extraction:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassNames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirsWavFeatureExtraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistOfDirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtWin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtStep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstWin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstStep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomputeBEAT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomputeBEAT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/andorkesselman/Documents/rnd/sound/src/lib/audioFeatureExtraction.py\u001b[0m in \u001b[0;36mdirsWavFeatureExtraction\u001b[0;34m(dirNames, mtWin, mtStep, stWin, stStep, computeBEAT)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0mclassNames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0mfileNames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirNames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirWavFeatureExtraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtWin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtStep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstWin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstStep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomputeBEAT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomputeBEAT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m       \u001b[0;31m# if at least one audio file has been found in the provided folder:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/andorkesselman/Documents/rnd/sound/src/lib/audioFeatureExtraction.py\u001b[0m in \u001b[0;36mdirWavFeatureExtraction\u001b[0;34m(dirName, mtWin, mtStep, stWin, stStep, computeBEAT)\u001b[0m\n\u001b[1;32m    741\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mMidTermFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstFeatures\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmtFeatureExtraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmtWin\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mFs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmtStep\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mFs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstWin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mbeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeatConf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeatExtraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mMidTermFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmtFeatureExtraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmtWin\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mFs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmtStep\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mFs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstWin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/andorkesselman/Documents/rnd/sound/src/lib/audioFeatureExtraction.py\u001b[0m in \u001b[0;36mmtFeatureExtraction\u001b[0;34m(signal, Fs, mtWin, mtStep, stWin, stStep)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0mmtFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m     \u001b[0mstFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstFeatureExtraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstWin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0mnumOfFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstFeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/andorkesselman/Documents/rnd/sound/src/lib/audioFeatureExtraction.py\u001b[0m in \u001b[0;36mstFeatureExtraction\u001b[0;34m(signal, Fs, Win, Step)\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0mnFFT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWin\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mfbank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmfccInitFilterBanks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnFFT\u001b[0m\u001b[0;34m)\u001b[0m                \u001b[0;31m# compute the triangular filter banks used in the mfcc calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m     \u001b[0mnChroma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnFreqsPerChroma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstChromaFeaturesInit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnFFT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/andorkesselman/Documents/rnd/sound/src/lib/audioFeatureExtraction.py\u001b[0m in \u001b[0;36mstChromaFeaturesInit\u001b[0;34m(nfft, fs)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0minitializes\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mchroma\u001b[0m \u001b[0mmatrices\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcalculation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mchroma\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \"\"\"\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ffffffffff\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnfft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0mfreqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnfft\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnfft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0mCp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m27.50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "aT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    print(\"Self\")\n",
    "#generateSamples(clean_dir_base,clean_dir_gen, \"clean\")\n",
    "#generateSamples(inter_dir_base,inter_dir_gen, \"inter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
